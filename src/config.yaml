model_name: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
dataset: causal_classification_inference
sample_size: 50
method: random

fpb:
  model_name: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
  max_tokens: 128
  temperature: 0.0
  top_p: 0.9
  top_k: 50
  repetition_penalty: 1.0

prompt_template: "Your prompt template here"
data_directory: "data"
seeds: [42, 123, 456]