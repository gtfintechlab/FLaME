{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tokens import tokens\n",
    "import os\n",
    "import dspy\n",
    "import textgrad\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokens\n",
    "os.environ['TOGETHER_API_KEY'] = together_token\n",
    "os.environ['HF_TOKEN'] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Participants agreed that the labor market had remained strong over the intermeeting period and that economic activity had risen at a moderate rate.\n",
      "Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikad\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Load testing data\n",
    "dataset = load_dataset(\"gtfintechlab/fomc_communication\")\n",
    "sample = dataset['test'][0]\n",
    "sentence = sample['sentence']\n",
    "label = sample['label']\n",
    "print(f\"Original sentence: {sentence}\\nLabel: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one in prompts.py was not returning just the system prompt/user message which together 1.2 needs\n",
    "def fomc_prompt(sentence: str):\n",
    "\n",
    "    system_prompt = f\"\"\"Discard all the previous instructions. Behave like you are an expert sentence clas-\n",
    "                sifier.\"\"\"\n",
    "    user_msg = f\"\"\"Classify the following sentence from FOMC into ‘HAWKISH’, ‘DOVISH’, or ‘NEU-\n",
    "                TRAL’ class. Label ‘HAWKISH’ if it is corresponding to tightening of the monetary policy,\n",
    "                ‘DOVISH’ if it is corresponding to easing of the monetary policy, or ‘NEUTRAL’ if the\n",
    "                stance is neutral. Provide the label in the first line and provide a short explanation in the\n",
    "                second line. This is the sentence: {sentence}\"\"\"\n",
    "\n",
    "    return system_prompt, user_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial textgrad testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral class\\nExplanation: The sentence indicates that participants agreed on the strong labor market and moderate economic activity, suggesting a neutral stance towards monetary policy.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic textgrad together engine\n",
    "engine = get_engine('together-allenai/OLMo-7B-Instruct')\n",
    "engine(fomc_prompt(sentence)[1], system_prompt = fomc_prompt(sentence)[0], max_tokens=128, temperature=0.7, top_p=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'Discard all the previous instructions. Behave like you are an expert sentence classifier.'\n",
    "engine = get_engine('together-mistralai/Mistral-7B-Instruct-v0.3')\n",
    "\n",
    "sys_prompt = Variable('Discard all the previous instructions. Behave like you are an expert sentence classifier.', role_description=\"The system prompt\")\n",
    "user_prompt = Variable(\"Classify the sentence's stance on the monetary policy between hawkish, neutral, and dovish.\", role_description=\"The user prompt\", requires_grad=True)\n",
    "input_sentence = Variable(sentence, role_description=\"The input sentence\")\n",
    "loss = TextLoss(sys_prompt, engine=engine)\n",
    "\n",
    "# optimization does not allow you to set any parameters besides prompt & system prompt\n",
    "# meaning you can't set max tokens or temperature --> problem b/c default output tokens is 2000 \n",
    "# so models with too small context windows will error\n",
    "\n",
    "optimizer = TextualGradientDescent(parameters=[user_prompt], engine=engine)\n",
    "l = loss(input_sentence)\n",
    "l.backward(engine)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine the monetary policy stance (hawkish, neutral, or dovish) expressed in the given sentence.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimized version of user prompt\n",
    "user_prompt.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textgrad Prompt Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_llm(response, label, eval_model):\n",
    "    response_var = Variable(f\"Response: {response.value}\\nTrue answer: {label.value}\", role_description=\"response to be evaluated\")\n",
    "    eval_response = eval_model(response_var)\n",
    "    eval_response = eval_response.value.strip().split(\" \")[0].lower()\n",
    "    return int(eval_response == \"yes\")\n",
    "\n",
    "def eval_sample(item, eval_fn, model, eval_model):\n",
    "    x, y = item\n",
    "    x = Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
    "    y = Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
    "    response = model(x)\n",
    "    return eval_fn(response, y, eval_model)\n",
    "    \n",
    "def eval_dataset(test_set, eval_fn, model, eval_model, max_samples = None):\n",
    "    if max_samples is None: \n",
    "        max_samples = len(test_set)\n",
    "    accuracy_list = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for _, sample in enumerate(test_set):\n",
    "            future = executor.submit(eval_sample, sample, eval_fn, model, eval_model)\n",
    "            futures.append(future)\n",
    "            if len(futures) >= max_samples:\n",
    "                break\n",
    "        tqdm_loader = tqdm(concurrent.futures.as_completed(futures), total=len(futures), position=0)\n",
    "        for future in tqdm_loader:\n",
    "            acc_item = future.result()\n",
    "            accuracy_list.append(acc_item)\n",
    "            tqdm_loader.set_description(f\"Accuracy: {np.mean(accuracy_list)}\")\n",
    "    return accuracy_list \n",
    "\n",
    "def run_validation_revert(system_prompt, results, eval_fn, model, eval_model, val_set):\n",
    "    val_accuracy = np.mean(eval_dataset(val_set, eval_fn, model, eval_model))\n",
    "    prev_accuracy = np.mean(results[\"val_accuracy\"][-1])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\\nPrevious validation accuracy: {prev_accuracy}\")\n",
    "    previous_prompt = results[\"prompt\"][-1]\n",
    "    \n",
    "    if val_accuracy < prev_accuracy:\n",
    "        print(f\"Rejected prompt: {system_prompt.value}\")\n",
    "        system_prompt.set_value(previous_prompt)\n",
    "        val_accuracy = prev_accuracy\n",
    "\n",
    "    results[\"val_accuracy\"].append(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine('together-mistralai/Mistral-7B-Instruct-v0.3')\n",
    "eval_prompt = Variable(\"Determine if the response matches the true answer. Respond with 'yes' or 'no'.\", \n",
    "                            requires_grad=False, role_description=\"evaluation prompt to the language model\")\n",
    "eval_model = textgrad.BlackboxLLM(engine, eval_prompt)\n",
    "\n",
    "starting_prompt = \"Classify the sentence's stance on the monetary policy between hawkish, neutral, and dovish.\"\n",
    "system_prompt = Variable(starting_prompt, requires_grad=True, role_description=\"system prompt to the language model\")\n",
    "model = textgrad.BlackboxLLM(engine, system_prompt)\n",
    "\n",
    "optimizer = TextualGradientDescent(engine=engine, parameters=[system_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5826612903225806: 100%|██████████| 496/496 [20:12<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# testing zero-shot performance\n",
    "mapping = {0: 'dovish', 1: 'hawkish', 2: 'neutral'}\n",
    "data = [(data['sentence'], mapping[data['label']]) for data in dataset['test']]\n",
    "results = {\"test_accuracy\": [], \"prompt\": []}\n",
    "results[\"test_accuracy\"].append(eval_dataset(data, eval_llm, model, eval_model))\n",
    "results[\"prompt\"].append(system_prompt.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data to do a mini run\n",
    "training_data = [(data['sentence'], mapping[data['label']]) for data in dataset['train']]\n",
    "testing_data = [(data['sentence'], mapping[data['label']]) for data in dataset['test']]\n",
    "random.shuffle(training_data)\n",
    "training_data = training_data[:30]\n",
    "val_data = training_data[-10:]\n",
    "testing_data = testing_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3: 100%|██████████| 10/10 [00:26<00:00,  2.63s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.3\n",
      "Previous validation accuracy: 0.0\n",
      "sys prompt:  Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a clear and concise response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:24<00:00,  2.45s/it]               \n",
      "Accuracy: 0.6: 100%|██████████| 10/10 [00:26<00:00,  2.61s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6\n",
      "Previous validation accuracy: 0.3\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:24<00:00,  2.44s/it]              \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 518.87it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 360.19it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 642.86it/s]     \n",
      "Training step 3. Epoch 0: : 3it [02:32, 50.91s/it]\n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 540.52it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 645.57it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 277.24it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 523.40it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 420.47it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 543.61it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 561.43it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 507.55it/s]     \n",
      "Training step 3. Epoch 1: : 3it [00:17,  5.68s/it]\n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 704.78it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 528.55it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 339.98it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 557.17it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 378.91it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 507.75it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 604.98it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 187.04it/s]     \n",
      "Training step 3. Epoch 2: : 3it [00:09,  3.05s/it]\n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 899.35it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 411.34it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 571.90it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 455.35it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 573.77it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 691.91it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 432.46it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 638.90it/s]     \n",
      "Training step 3. Epoch 3: : 3it [00:01,  2.52it/s]\n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 527.03it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 451.86it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 173.79it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 363.78it/s]     \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 511.61it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 1038.89it/s]    \n",
      "Accuracy: 0.5: 100%|██████████| 10/10 [00:00<00:00, 587.89it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5\n",
      "Previous validation accuracy: 0.6\n",
      "Rejected prompt: Identify and classify the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, providing a concise and clear response.\n",
      "sys prompt:  Determine and categorize the monetary policy stance (hawkish, neutral, or dovish) in the given sentence, offering a succinct and clear response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7: 100%|██████████| 10/10 [00:00<00:00, 429.21it/s]     \n",
      "Training step 3. Epoch 4: : 3it [00:08,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {\"test_accuracy\": [0], \"prompt\": [\"Classify the sentence's stance on the monetary policy between hawkish, neutral, and dovish.\"], \"val_accuracy\": [0]}\n",
    "train_loader = textgrad.tasks.DataLoader(training_data, batch_size=3, shuffle=True)\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for steps, (batch_x, batch_y) in enumerate((pbar := tqdm(train_loader, position=0))):\n",
    "        pbar.set_description(f\"Training step {steps}. Epoch {epoch}\")\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "        for (x, y) in zip(batch_x, batch_y):\n",
    "            eval_var = eval_sample((x, y), eval_llm, model, eval_model)\n",
    "            eval_var = Variable(str(eval_var), requires_grad=False, role_description=\"evaluation variable\")\n",
    "            losses.append(eval_var)\n",
    "        total_loss = textgrad.sum(losses)\n",
    "        total_loss.backward(engine)\n",
    "        optimizer.step()\n",
    "        \n",
    "        run_validation_revert(system_prompt, results, eval_llm, model, eval_model, val_data)\n",
    "        \n",
    "        print(\"sys prompt: \", system_prompt)\n",
    "        test_acc = eval_dataset(testing_data, eval_llm, model, eval_model)\n",
    "        results[\"test_accuracy\"].append(test_acc)\n",
    "        results[\"prompt\"].append(system_prompt.get_value())\n",
    "        if steps == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing together 1.2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: Neutral class\n",
      "Explanation: The sentence mentions that participants agreed that the labor market remained strong and economic activity rose at a moderate rate, indicating a neutral stance towards monetary policy.\n",
      "Token usage: {'prompt_tokens': 174, 'response_tokens': 37, 'total_tokens': 211}\n"
     ]
    }
   ],
   "source": [
    "# Testing together 1.2 API\n",
    "client = Together()\n",
    "model_response = client.chat.completions.create(\n",
    "    model='allenai/OLMo-7B-Instruct',\n",
    "    messages=[{'role': 'system', 'content': fomc_prompt(sentence)[0]},\n",
    "                {'role': 'user', 'content': fomc_prompt(sentence)[1]}],\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.7,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "response_label = model_response.choices[0].message.content\n",
    "token_usage = {'prompt_tokens': model_response.usage.prompt_tokens, 'response_tokens': model_response.usage.completion_tokens, 'total_tokens': model_response.usage.total_tokens}\n",
    "print(f\"LLM response: {response_label.strip()}\\nToken usage: {token_usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function Together._generate at 0x0000017878ABF700> with kwargs {'temperature': 0.0, 'max_tokens': 512, 'top_p': 1, 'top_k': 20, 'repetition_penalty': 1, 'n': 1, 'stop': ['</s>', '<s>']}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function Together._generate at 0x0000017878ABF700> with kwargs {'temperature': 0.0, 'max_tokens': 512, 'top_p': 1, 'top_k': 20, 'repetition_penalty': 1, 'n': 1, 'stop': ['</s>', '<s>']}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function Together._generate at 0x0000017878ABF700> with kwargs {'temperature': 0.0, 'max_tokens': 512, 'top_p': 1, 'top_k': 20, 'repetition_penalty': 1, 'n': 1, 'stop': ['</s>', '<s>']}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function Together._generate at 0x0000017878ABF700> with kwargs {'temperature': 0.0, 'max_tokens': 512, 'top_p': 1, 'top_k': 20, 'repetition_penalty': 1, 'n': 1, 'stop': ['</s>', '<s>']}\n",
      "Backing off 12.9 seconds after 5 tries calling function <function Together._generate at 0x0000017878ABF700> with kwargs {'temperature': 0.0, 'max_tokens': 512, 'top_p': 1, 'top_k': 20, 'repetition_penalty': 1, 'n': 1, 'stop': ['</s>', '<s>']}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\modules\\hf_client.py\u001b[0m in \u001b[0;36m_generate\u001b[1;34m(self, prompt, use_chat_api, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m                 \u001b[0mresp_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    574\u001b[0m         )\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         p.prepare(\n\u001b[0m\u001b[0;32m    485\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             raise MissingSchema(\n\u001b[0m\u001b[0;32m    439\u001b[0m                 \u001b[1;34mf\"Invalid URL {url!r}: No scheme supplied. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\backoff\\_sync.py\u001b[0m in \u001b[0;36mretry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\modules\\hf_client.py\u001b[0m in \u001b[0;36m_generate\u001b[1;34m(self, prompt, use_chat_api, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mresp_json\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"resp_json:{resp_json}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'resp_json' referenced before assignment",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16016/1839701109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0manalyze\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dspy\\primitives\\program.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnamed_predictors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16016/1839701109.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0manalyze\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dspy\\predict\\predict.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dspy\\predict\\predict.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Note: query_only=True means the instructions and examples are not included.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\primitives\\predict.py\u001b[0m in \u001b[0;36mdo_generate\u001b[1;34m(example, stage, max_depth, original_example)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m# Generate and extract the fields.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mcompletions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mcompletions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mExample\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\modules\\hf.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"do_sample\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\modules\\lm.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_green\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\dsp\\modules\\hf.py\u001b[0m in \u001b[0;36mbasic_request\u001b[1;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mraw_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         history = {\n",
      "\u001b[1;32mc:\\Users\\mikad\\anaconda3\\lib\\site-packages\\backoff\\_sync.py\u001b[0m in \u001b[0;36mretry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m                                exception=e)\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0m_call_handlers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdetails\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# testing dspy\n",
    "# dspy together module has some issues with how they wrote it (passing specific parameters is hard)\n",
    "# rate limiting error messages\n",
    "# TODO: look into dspy together module more to see how to fix it\n",
    "\n",
    "lm = dspy.Together(model = 'mistralai/Mistral-7B-Instruct-v0.3', stop = ['</s>', '<s>'])\n",
    "dspy.settings.configure(lm=lm)\n",
    "d = {0: 'dovish', 1: 'hawkish', 2: 'neutral'}\n",
    "\n",
    "class StanceAnalysis(dspy.Signature):\n",
    "    \"\"\"Classify the sentence's stance on the monetary policy between hawkish, neutral, and dovish.\"\"\"\n",
    "    \n",
    "    sentence = dspy.InputField()\n",
    "    stance = dspy.OutputField(desc = \"hawkish, neutral, or dovish\")\n",
    "\n",
    "class Analysis(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict = dspy.Predict(StanceAnalysis)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        return self.predict(sentence=sentence)\n",
    "    \n",
    "analyze = Analysis()\n",
    "analyze(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
