{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6755a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e7f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "from tqdm.auto import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c87e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "# transformers.logging.set_verbosity_error()\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, LlamaModel, LlamaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae084e26-5870-4fb7-89d1-4744dfa6e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdade010",
   "metadata": {},
   "source": [
    "#### Llama2 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64fd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "model_cache = os.path.join(os.path.expanduser(\"~\"), f\"models_hf/{model_id.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24973fee",
   "metadata": {},
   "source": [
    "# TODO: SET UP LLAMA CONFIGS FOR THE MODEL\n",
    "\n",
    "# Initializing a LLaMA llama-7b style configuration\n",
    "configuration = LlamaConfig()\n",
    "\n",
    "# Initializing a model from the llama-7b style configuration\n",
    "model = LlamaModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b32596",
   "metadata": {},
   "source": [
    "#### HuggingFace Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b677872",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_auth = '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'\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d29ab",
   "metadata": {},
   "source": [
    "#### BitsAndBytes Config"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aed4c5f9",
   "metadata": {},
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4ce8b",
   "metadata": {},
   "source": [
    "#### Tokenizer Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2988e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    legacy=False,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39bcd6",
   "metadata": {},
   "source": [
    "#### Model Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81998caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LlamaForCausalLM.__init__() got an unexpected keyword argument 'repetition_penalty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;43;03m#     quantization_config=bnb_config,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_auth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/zero/lib/python3.11/site-packages/transformers/modeling_utils.py:2700\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 2700\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "\u001b[0;31mTypeError\u001b[0m: LlamaForCausalLM.__init__() got an unexpected keyword argument 'repetition_penalty'"
     ]
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "#     quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "224758c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    temperature=0.0,  # [0.0, 1.0]\n",
    "    do_sample=False, # Turns off logit-based sampling; enable if setting `temperature` > 0\n",
    "    max_new_tokens=512,  # Max number of tokens to generate\n",
    "    top_k=10,\n",
    "    top_p=0.92,\n",
    "    # repetition_penalty=1.02,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3327ec-4b4d-4bcb-bd55-7878f9a8992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =(\n",
    "    \"Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .\"\n",
    ", \"CapMan 's first real estate fund , which had a total investment capacity of ( EURO ) 500 million and closed in June 2005 , invested in commercial properties in the Helsinki metropolitan area .\"\n",
    ", \"The value of the contracts is about EUR 3.3 mn .\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c325eb18-f608-4b41-be20-e8073217df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama2_prompt_generator(sentences: list[str]):\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "    BOS, EOS = \"<s>\", \"</s>\"\n",
    "    SYS_PROMPT = f\"\"\"\"Discard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\"\"\n",
    "    INST_PROMPT = f\"\"\"Behave like you are an expert sentence sentiment classifier. Classify the following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label 'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: \"\"\"\n",
    "\n",
    "    if not sentences or not all(isinstance(sentence, str) for sentence in sentences):\n",
    "        raise ValueError(\"Input must be a non-empty list of strings.\")\n",
    "\n",
    "    prompts = []\n",
    "    for sentence in sentences:\n",
    "        prompt = B_INST + B_SYS + SYS_PROMPT + E_SYS + INST_PROMPT + sentence + E_INST\n",
    "        # prompt_content = ' '.join(B_INST, B_SYS, SYS_PROMPT, E_SYS, INST_PROMPT, sentence, E_INST) # TODO: determine if whitespace hurts the results\n",
    "        # formatted_prompt = f\"{BOS}{B_INST} {prompt_content} {E_INST}{EOS}\" # i do not think BOS/EOS should be used with HF tokenizer\n",
    "        # formatted_prompt = f\"\"\"{prompt_content}\"\"\"\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12cdfe07-44f6-4b36-9182-8f14a6350d5d",
   "metadata": {},
   "source": [
    "def build_llama2_prompt(messages):\n",
    "    startPrompt = \"<s>[INST] \"\n",
    "    endPrompt = \" [/INST]\"\n",
    "    conversation = []\n",
    "    for index, message in enumerate(messages):\n",
    "        if message[\"role\"] == \"system\" and index == 0:\n",
    "            conversation.append(f\"<<SYS>>\\n{message['content']}\\n<</SYS>>\\n\\n\")\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            conversation.append(message[\"content\"].strip())\n",
    "        else:\n",
    "            conversation.append(f\" [/INST] {message.content}</s><s>[INST] \")\n",
    "\n",
    "    return startPrompt + \"\".join(conversation) + endPrompt\n",
    "  \n",
    "messages = [\n",
    "  { \"role\": \"system\",\"content\": \"You are a friendly and knowledgeable vacation planning assistant named Clara. Your goal is to have natural conversations with users to help them plan their perfect vacation. \"}\n",
    "]\n",
    "\n",
    "# define question and add to messages\n",
    "instruction = \"What are some cool ideas to do in the summer?\"\n",
    "messages.append({\"role\": \"user\", \"content\": instruction})\n",
    "prompt = build_llama2_prompt(messages)\n",
    "\n",
    "chat = llm.predict({\"inputs\":prompt})\n",
    "\n",
    "print(chat[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d0175b-b053-4d2e-810a-28514a12d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = llama2_prompt_generator(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb5c8dfa-61da-4532-8b30-982ca0dabc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST]<<SYS>>\\nDiscard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n<</SYS>>\\n\\nBehave like you are an expert sentence sentiment classifier. Classify the following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label 'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .[/INST]\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd7788b3-7c52-469f-89df-81010a47cf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882aaf1db7ab458e893496010bb4554a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 s, sys: 404 ms, total: 26.2 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences = []\n",
    "for prompt in tqdm(prompts):\n",
    "    sequences.append(llama2_pipeline(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "160d064c-319d-49de-875a-2c09769cfed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST]<<SYS>>\\nDiscard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n<</SYS>>\\n\\nBehave like you are an expert sentence sentiment classifier. Classify the following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label 'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .[/INST]  Sure! Here's my response:\\n\\nLabel: NEUTRAL\\n\\nExplanation: The sentence provides a list of countries where the company's customers are located, without expressing any explicit sentiment. The tone is informative and factual, and there is no hint of negative or positive emotion, so the sentiment is neutral.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0][0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6526dc1e-01fa-4d6d-8cd5-4263ebc4a85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[INST]<<SYS>>\\n'\n",
      " 'Discard all the previous instructions. Below is an instruction that '\n",
      " 'describes a task. Write a response that appropriately completes the '\n",
      " 'request.\\n'\n",
      " '<</SYS>>\\n'\n",
      " '\\n'\n",
      " 'Behave like you are an expert sentence sentiment classifier. Classify the '\n",
      " \"following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label \"\n",
      " \"'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is \"\n",
      " \"corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is \"\n",
      " 'neutral. Provide the label in the first line and provide a short explanation '\n",
      " 'in the second line. The sentence: Our customers come from the following '\n",
      " 'countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong '\n",
      " ', Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech '\n",
      " 'Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South '\n",
      " \"Korea and Liechtenstein .[/INST]  Sure! Here's my response:\\n\"\n",
      " '\\n'\n",
      " 'Label: NEUTRAL\\n'\n",
      " '\\n'\n",
      " \"Explanation: The sentence provides a list of countries where the company's \"\n",
      " 'customers are located, without expressing any explicit sentiment. The tone '\n",
      " 'is informative and factual, and there is no hint of negative or positive '\n",
      " 'emotion, so the sentiment is neutral.')\n",
      "('[INST]<<SYS>>\\n'\n",
      " 'Discard all the previous instructions. Below is an instruction that '\n",
      " 'describes a task. Write a response that appropriately completes the '\n",
      " 'request.\\n'\n",
      " '<</SYS>>\\n'\n",
      " '\\n'\n",
      " 'Behave like you are an expert sentence sentiment classifier. Classify the '\n",
      " \"following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label \"\n",
      " \"'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is \"\n",
      " \"corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is \"\n",
      " 'neutral. Provide the label in the first line and provide a short explanation '\n",
      " \"in the second line. The sentence: CapMan 's first real estate fund , which \"\n",
      " 'had a total investment capacity of ( EURO ) 500 million and closed in June '\n",
      " '2005 , invested in commercial properties in the Helsinki metropolitan area '\n",
      " \".[/INST]  Sure, I'd be happy to help! Here's my response:\\n\"\n",
      " '\\n'\n",
      " 'Label: NEUTRAL\\n'\n",
      " '\\n'\n",
      " 'Explanation: The sentence describes a past investment made by CapMan, a real '\n",
      " 'estate fund, in commercial properties in the Helsinki metropolitan area. The '\n",
      " 'tone of the sentence is factual and informative, without any apparent '\n",
      " 'positive or negative sentiment. Therefore, I have classified the sentence as '\n",
      " 'NEUTRAL.')\n",
      "('[INST]<<SYS>>\\n'\n",
      " 'Discard all the previous instructions. Below is an instruction that '\n",
      " 'describes a task. Write a response that appropriately completes the '\n",
      " 'request.\\n'\n",
      " '<</SYS>>\\n'\n",
      " '\\n'\n",
      " 'Behave like you are an expert sentence sentiment classifier. Classify the '\n",
      " \"following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label \"\n",
      " \"'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is \"\n",
      " \"corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is \"\n",
      " 'neutral. Provide the label in the first line and provide a short explanation '\n",
      " 'in the second line. The sentence: The value of the contracts is about EUR '\n",
      " \"3.3 mn .[/INST]  Sure, I'd be happy to help!\\n\"\n",
      " '\\n'\n",
      " 'Label: NEUTRAL\\n'\n",
      " '\\n'\n",
      " 'Explanation: The sentence \"The value of the contracts is about EUR 3.3 mn\" '\n",
      " 'is neutral as it simply states a fact about the value of the contracts '\n",
      " 'without expressing any emotion or opinion. There is no indication of '\n",
      " 'positive or negative sentiment in the sentence.')\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "    pp.pprint(seq[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ae381-0cfa-4e7c-9079-e9b6f279625d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (zero)",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
