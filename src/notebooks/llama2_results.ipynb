{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5fd829d5-c45e-41ee-81d3-2bea83e9cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8651e6a7-8000-4476-b32b-50222c4df59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('llama2_results')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "consoleHandler.setFormatter(formatter)\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29878e67-9f12-4a9e-b90f-1d2e28210b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 20:12:59,421 - llama2_results - INFO - Root directory: /Users/glenn/PycharmProjects/zero-shot-finance\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIRECTORY = Path().resolve().parent.parent\n",
    "logger.info(f\"Root directory: {str(ROOT_DIRECTORY)}\")\n",
    "if str(ROOT_DIRECTORY) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46835012-a3fe-48e8-b8e7-b39e9ec37ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'sentiment_analysis'\n",
    "quantizations = ['fp16','bf16','int8','fp4']\n",
    "model_ids = [f\"meta-llama/Llama-2-{n}b-chat-hf\" for n in (7, 13, 70)]\n",
    "model_names = [id.split('/')[-1] for id in model_ids]\n",
    "hf_auth = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "087b8242-290a-4969-b786-7a1a7fd13545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(text_output, E_INST = \"[/INST]\"):\n",
    "    # Find the 'end of instruction' token and remove text before it\n",
    "    response_pos = text_output.find(E_INST)\n",
    "    generated_text = text_output[response_pos + len(E_INST) :].strip()\n",
    "    # Convert the string to lowercase for case-insensitive search\n",
    "    text = text_output.lower()\n",
    "    \n",
    "    # Define the substring options\n",
    "    substrings = [\"label: positive\", \"label: negative\", \"label: neutral\"]\n",
    "    \n",
    "    # Iterate over the substrings and find the matching label\n",
    "    for i, substring in enumerate(substrings):\n",
    "        if substring in text:\n",
    "            return i\n",
    "    \n",
    "    # If none of the substrings are found, return -1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f7a4b83-7c92-43a8-8994-907fe6f7dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(files, outputs_directory):\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    missing_perc_list = []\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(outputs_directory / file)\n",
    "\n",
    "        # Make sure the 'Label:' was provided in all generated text\n",
    "        if all(df['text_output'].str.contains('Label:')):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"not all responses contain the substring 'Label:'\")\n",
    "\n",
    "        # Decode the predicted label\n",
    "        df[\"generated_label\"] = df[\"text_output\"].apply(extract_label)\n",
    "\n",
    "        # Calculate metrics\n",
    "        acc_list.append(accuracy_score(df[\"true_label\"], df[\"generated_label\"]))\n",
    "        f1_list.append(\n",
    "            f1_score(df[\"true_label\"], df[\"generated_label\"], average=\"weighted\")\n",
    "        )\n",
    "        missing_perc_list.append(\n",
    "            (len(df[df[\"generated_label\"] == -1]) / df.shape[0]) * 100.0\n",
    "        )\n",
    "\n",
    "    return acc_list, f1_list, missing_perc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd4f9236-aab4-436d-98ea-d92e8d4fba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model_name in model_names:\n",
    "    results[model_name] = {}\n",
    "    for quantization in quantizations:\n",
    "        # Define output directory\n",
    "        LLM_OUTPUTS_DIRECTORY = (\n",
    "            ROOT_DIRECTORY\n",
    "            / \"data\"\n",
    "            / task_name\n",
    "            / \"llm_prompt_outputs\"\n",
    "            / quantization\n",
    "        )\n",
    "        # Filter out relevant files\n",
    "        files = [\n",
    "            f.stem\n",
    "            for f in LLM_OUTPUTS_DIRECTORY.iterdir()\n",
    "            if model_name in f.name and f.suffix == \".csv\"\n",
    "        ]\n",
    "        results[model_name][quantization] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "131f98ca-5c70-488d-95f8-7649aee2925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Llama-2-13b-chat-hf': { 'bf16': [ 'Llama-2-13b-chat-hf_944601_10_08_2023_41',\n",
      "                                     'Llama-2-13b-chat-hf_78516_10_08_2023_41',\n",
      "                                     'Llama-2-13b-chat-hf_5768_10_08_2023_41'],\n",
      "                           'fp16': [ 'Llama-2-13b-chat-hf_78516_10_08_2023_72',\n",
      "                                     'Llama-2-13b-chat-hf_5768_10_08_2023_70',\n",
      "                                     'Llama-2-13b-chat-hf_944601_10_08_2023_71'],\n",
      "                           'fp4': [ 'Llama-2-13b-chat-hf_5768_10_08_2023_37',\n",
      "                                    'Llama-2-13b-chat-hf_78516_10_08_2023_37',\n",
      "                                    'Llama-2-13b-chat-hf_944601_10_08_2023_36'],\n",
      "                           'int8': [ 'Llama-2-13b-chat-hf_5768_10_08_2023_118',\n",
      "                                     'Llama-2-13b-chat-hf_78516_10_08_2023_121']},\n",
      "  'Llama-2-70b-chat-hf': { 'bf16': [],\n",
      "                           'fp16': [],\n",
      "                           'fp4': [ 'Llama-2-70b-chat-hf_944601_10_08_2023_97',\n",
      "                                    'Llama-2-70b-chat-hf_78516_10_08_2023_95',\n",
      "                                    'Llama-2-70b-chat-hf_5768_10_08_2023_95'],\n",
      "                           'int8': []},\n",
      "  'Llama-2-7b-chat-hf': { 'bf16': [ 'Llama-2-7b-chat-hf_78516_10_08_2023_25',\n",
      "                                    'Llama-2-7b-chat-hf_5768_10_08_2023_24',\n",
      "                                    'Llama-2-7b-chat-hf_944601_10_08_2023_25'],\n",
      "                          'fp16': [ 'Llama-2-7b-chat-hf_78516_10_08_2023_40',\n",
      "                                    'Llama-2-7b-chat-hf_5768_10_08_2023_40',\n",
      "                                    'Llama-2-7b-chat-hf_944601_10_08_2023_41'],\n",
      "                          'fp4': [ 'Llama-2-7b-chat-hf_78516_10_08_2023_31',\n",
      "                                   'Llama-2-7b-chat-hf_5768_10_08_2023_30',\n",
      "                                   'Llama-2-7b-chat-hf_944601_10_08_2023_31'],\n",
      "                          'int8': [ 'Llama-2-7b-chat-hf_78516_10_08_2023_95',\n",
      "                                    'Llama-2-7b-chat-hf_5768_10_08_2023_93',\n",
      "                                    'Llama-2-7b-chat-hf_944601_10_08_2023_94']}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "658b3db9-42ba-4e24-b418-4b6c9107cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE Llama-2-7b-chat-hf fp16\n",
      "DONE Llama-2-7b-chat-hf bf16\n",
      "DONE Llama-2-7b-chat-hf int8\n",
      "DONE Llama-2-7b-chat-hf fp4\n",
      "DONE Llama-2-13b-chat-hf fp16\n",
      "DONE Llama-2-13b-chat-hf bf16\n",
      "WIP Llama-2-13b-chat-hf int8\n",
      "DONE Llama-2-13b-chat-hf fp4\n",
      "EMPTY Llama-2-70b-chat-hf fp16\n",
      "EMPTY Llama-2-70b-chat-hf bf16\n",
      "EMPTY Llama-2-70b-chat-hf int8\n",
      "DONE Llama-2-70b-chat-hf fp4\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    for quantization in quantizations:\n",
    "        files = results[model_name][quantization]\n",
    "        if not files:\n",
    "            print('EMPTY', model_name, quantization)\n",
    "        elif len(files) == 3:\n",
    "            print('DONE', model_name, quantization)\n",
    "        elif len(files) < 3:\n",
    "            print('WIP', model_name, quantization)\n",
    "        else:\n",
    "            print('ERROR!', model_name, quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36a20a90-4873-497d-84cc-eb6f21a9275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score mean:  0.8818\n",
      "f1 score std:  0.0151\n",
      "Percentage of cases when didn't follow instruction:  0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_list, f1_list, missing_perc_list = compute_metrics(files, LLM_OUTPUTS_DIRECTORY)\n",
    "\n",
    "# Print results\n",
    "print(\"f1 score mean: \", format(np.mean(f1_list), \".4f\"))\n",
    "print(\"f1 score std: \", format(np.std(f1_list), \".4f\"))\n",
    "print(\n",
    "    \"Percentage of cases when didn't follow instruction: \",\n",
    "    format(np.mean(missing_perc_list), \".4f\"),\n",
    "    \"\\n\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
