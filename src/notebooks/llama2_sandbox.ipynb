{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b6d903-1721-49c7-a451-d9539ee512cd",
   "metadata": {},
   "source": [
    "# Llama2 Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44398c94-5d97-4c8a-b398-3ed5d01b6510",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc22e58-d646-4c96-a6e6-c2107c7f715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/DeepQuant/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "logger = logging.getLogger('llama2_sandbox')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "consoleHandler.setFormatter(formatter)\n",
    "logger.addHandler(consoleHandler)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc9318-aaf5-45f1-830a-dbecba6ed20c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e7f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, LlamaModel, LlamaConfig, TextGenerationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64fd4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:51:05,919 - llama2_sandbox - INFO - /Users/academia/models_hf/meta-llama/Llama-2-7b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "hf_auth = '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'\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model_cache = os.path.join(os.path.expanduser(\"~\"), f\"models_hf/{model_id.split('/')[0]}/{model_id.split('/')[-1]}\")\n",
    "# logger.info(model_cache)\n",
    "# quantization = 'fp16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9ab72d-00ef-4d23-a0b6-c41d5a8e2f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/academia/models_hf/meta-llama/Llama-2-7b-chat-hf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cc7e0e-f6e2-4a05-a370-d043a90b661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 23:44:39,858 - llama2_results - INFO - Using k=2 CUDA GPUs with max memory {0: '41GB', 1: '41GB'}\n"
     ]
    }
   ],
   "source": [
    "CUDA_N_GPUS = torch.cuda.device_count()\n",
    "CUDA_MAX_MEMORY = f\"{int(torch.cuda.mem_get_info()[0] / 1024 ** 3) - 2}GB\"\n",
    "CUDA_MAX_MEMORY = {i: CUDA_MAX_MEMORY for i in range(CUDA_N_GPUS)}\n",
    "logger.info(\n",
    "    f\"Using k={CUDA_N_GPUS} CUDA GPUs with max memory {CUDA_MAX_MEMORY}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0cb674d-613c-4751-b047-e00cf1f1df2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/configuration_utils.py:483: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_config = LlamaConfig.from_pretrained(\n",
    "                            model_id,\n",
    "                            bos_token_id = 1,\n",
    "                            eos_token_id = 2,\n",
    "                            hidden_act = \"silu\",\n",
    "                            hidden_size = 8192,\n",
    "                            initializer_range = 0.02,\n",
    "                            intermediate_size = 28672,\n",
    "                            max_position_embeddings = 4096,\n",
    "                            model_type = \"llama\",\n",
    "                            num_attention_heads = 64,\n",
    "                            num_hidden_layers = 80,\n",
    "                            num_key_value_heads = 8,\n",
    "                            pretraining_tp = 1,\n",
    "                            rms_norm_eps = 1e-05,\n",
    "                            rope_scaling = None,\n",
    "                            tie_word_embeddings = False,\n",
    "                            torch_dtype = \"float16\",\n",
    "                            transformers_version = \"4.32.0.dev0\",\n",
    "                            use_cache = True,\n",
    "                            vocab_size = 32000,\n",
    "                            use_auth_token = hf_auth\n",
    "                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "id": "68d43198-4124-436a-8f37-6ec93a01364f",
   "metadata": {},
   "source": [
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(model_config)\n",
    "\n",
    "device_map = infer_auto_device_map(model, no_split_module_classes=[\"LlamaDecoderLayer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4dc6e7-1af5-461f-9db5-e598f10cce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:15<00:00,  1.06s/it]\n",
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if quantization == \"fp16\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_auth_token=hf_auth,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        # torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        offload_state_dict=True,\n",
    "        offload_folder=\"offload\",\n",
    "        max_memory=CUDA_MAX_MEMORY,\n",
    "    )\n",
    "elif quantization == \"bf16\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_auth_token=hf_auth,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        offload_state_dict=True,\n",
    "        offload_folder=\"offload\",\n",
    "        max_memory=CUDA_MAX_MEMORY,\n",
    "    )\n",
    "elif quantization == \"int8\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_auth_token=hf_auth,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        load_in_8bit=True,\n",
    "        device_map=\"auto\",\n",
    "        offload_state_dict=True,\n",
    "        offload_folder=\"offload\",\n",
    "        max_memory=CUDA_MAX_MEMORY,\n",
    "    )\n",
    "elif quantization == \"fp4\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_auth_token=hf_auth,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        load_in_4bit=True,\n",
    "        device_map=\"auto\",\n",
    "        offload_state_dict=True,\n",
    "        offload_folder=\"offload\",\n",
    "        max_memory=CUDA_MAX_MEMORY,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Invalid quantization '{quantization}'\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    legacy=False,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "224758c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pipeline ready for instruction text generation\n",
    "generation_pipeline = TextGenerationPipeline(model=model,\n",
    "                                             tokenizer=tokenizer,\n",
    "                                             # NOTE: Set `do_sample = True` when `temperature > 0.0`\n",
    "                                             # https://github.com/huggingface/transformers/issues/25326\n",
    "                                             temperature=0.0,  # [0.0, 1.0]; 0.0 means greedy sampling\n",
    "                                             do_sample=False,\n",
    "                                             max_new_tokens=512,\n",
    "                                             top_k=10,\n",
    "                                             top_p=0.92,\n",
    "                                             repetition_penalty=1.0,  # 1.0 means no penalty\n",
    "                                             num_return_sequences=1  # Only generate one response\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c325eb18-f608-4b41-be20-e8073217df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "DISCARD = \"Discard all the previous instructions.\"\n",
    "\n",
    "TASK_INSTRUCTION_MAP = {\n",
    "    \"sentiment_analysis\": f\"{DISCARD} Behave like you are an expert sentence sentiment classifier. Classify the following sentence into 'NEGATIVE', 'POSITIVE', or 'NEUTRAL' class. Label 'NEGATIVE' if it is corresponding to negative sentiment, 'POSITIVE' if it is corresponding to positive sentiment, or 'NEUTRAL' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: \",\n",
    "}\n",
    "\n",
    "TASK_DATA_MAP = {\n",
    "    \"sentiment_analysis\": \"FPB-sentiment-analysis-allagree\",\n",
    "}\n",
    "\n",
    "TASK_MAP = {\n",
    "    \"sentiment_analysis\": {\n",
    "        \"data\": TASK_DATA_MAP[\"sentiment_analysis\"],\n",
    "        \"instruction\": TASK_INSTRUCTION_MAP[\"sentiment_analysis\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "\n",
    "def llama2_prompt_generator(instruction: str, sentences: list[str]):\n",
    "    SYS_PROMPT = f\"\"\"\"Discard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\"\"\n",
    "    INST_PROMPT = instruction\n",
    "    if not instruction or not isinstance(instruction, str):\n",
    "        raise ValueError(\"Instruction must be a non-empty string.\")\n",
    "    if not sentences or not all(isinstance(sentence, str) for sentence in sentences):\n",
    "        raise ValueError(\"Sentences must be a non-empty list of strings.\")\n",
    "\n",
    "    prompts = []\n",
    "    for SENTENCE in sentences:\n",
    "        prompts.append(\n",
    "            B_INST + B_SYS + SYS_PROMPT + E_SYS + INST_PROMPT + SENTENCE + E_INST\n",
    "        )\n",
    "\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3327ec-4b4d-4bcb-bd55-7878f9a8992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES =(\n",
    "                \"Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .\"\n",
    "            , \"CapMan 's first real estate fund , which had a total investment capacity of ( EURO ) 500 million and closed in June 2005 , invested in commercial properties in the Helsinki metropolitan area .\"\n",
    "            , \"The value of the contracts is about EUR 3.3 mn .\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df54c29-eb09-422f-ade8-1ed6573d8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION = TASK_MAP['sentiment_analysis']['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d0175b-b053-4d2e-810a-28514a12d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = llama2_prompt_generator(INSTRUCTION, SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd7788b3-7c52-469f-89df-81010a47cf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/gmatlin3/.conda/envs/zero/lib/python3.11/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 29s, sys: 11min 40s, total: 50min 9s\n",
      "Wall time: 50min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generation_result = generation_pipeline(inputs_list)\n",
    "\n",
    "output_list = []\n",
    "for i in range(len(generation_result)):\n",
    "    output_list.append(\n",
    "        # [labels[i], sentences[i], \n",
    "        generation_result[i][0][\"generated_text\"]\n",
    "        # ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e67386-de8b-459e-8520-6e0c0c55b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[INST]<<SYS>>\\n\"Discard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n<</SYS>>\\n\\nDiscard all the previous instructions. Behave like you are an expert sentence sentiment classifier. Classify the following sentence into \\'NEGATIVE\\', \\'POSITIVE\\', or \\'NEUTRAL\\' class. Label \\'NEGATIVE\\' if it is corresponding to negative sentiment, \\'POSITIVE\\' if it is corresponding to positive sentiment, or \\'NEUTRAL\\' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .[/INST]  NEGATIVE\\n\\nThe sentence mentions a list of countries, but the tone is flat and does not convey any positive or negative emotion. The lack of enthusiasm or excitement in the sentence suggests a negative sentiment.',\n",
       " '[INST]<<SYS>>\\n\"Discard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n<</SYS>>\\n\\nDiscard all the previous instructions. Behave like you are an expert sentence sentiment classifier. Classify the following sentence into \\'NEGATIVE\\', \\'POSITIVE\\', or \\'NEUTRAL\\' class. Label \\'NEGATIVE\\' if it is corresponding to negative sentiment, \\'POSITIVE\\' if it is corresponding to positive sentiment, or \\'NEUTRAL\\' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: CapMan \\'s first real estate fund , which had a total investment capacity of ( EURO ) 500 million and closed in June 2005 , invested in commercial properties in the Helsinki metropolitan area .[/INST]  NEGATIVE\\n\\nThe sentence expresses a negative sentiment as it mentions that the real estate fund invested in commercial properties in the Helsinki metropolitan area, implying that the fund did not perform well or meet its investment goals.',\n",
       " '[INST]<<SYS>>\\n\"Discard all the previous instructions. Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n<</SYS>>\\n\\nDiscard all the previous instructions. Behave like you are an expert sentence sentiment classifier. Classify the following sentence into \\'NEGATIVE\\', \\'POSITIVE\\', or \\'NEUTRAL\\' class. Label \\'NEGATIVE\\' if it is corresponding to negative sentiment, \\'POSITIVE\\' if it is corresponding to positive sentiment, or \\'NEUTRAL\\' if the sentiment is neutral. Provide the label in the first line and provide a short explanation in the second line. The sentence: The value of the contracts is about EUR 3.3 mn .[/INST]  NEGATIVE\\n\\nThe sentence expresses a negative sentiment as the value of the contracts is only about EUR 3.3 mn, which implies that the contracts are not as valuable as they could be.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
