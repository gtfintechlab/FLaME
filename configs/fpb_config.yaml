models:
  inference: "together_ai/meta-llama/Llama-3.1-8B-Instruct-Turbo"
  extraction: "together_ai/meta-llama/Llama-3.1-8B-Instruct-Turbo"

# Core settings
dataset: fpb
mode: inference  # inference or evaluate
file_name: null  # Required for evaluate mode

# Model parameters
max_tokens: 128
temperature: 0.0
top_p: 0.9
top_k: null
repetition_penalty: 1.0
batch_size: 10

# Dataset parameters
dataset_org: "gtfintechlab"
sample_size: 1
method: null
seeds: null
splits: null

# Other parameters
prompt_format: "superflue"