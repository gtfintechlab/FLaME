# Core settings
dataset: fomc
mode: inference
file_name: null

# Model parameters
model: "together_ai/meta-llama/Llama-3-8b-chat-hf"
max_tokens: 32
temperature: 0.0
top_p: 0.9
top_k: null
repetition_penalty: 1.0
batch_size: 250

# Dataset parameters
dataset_org: "gtfintechlab"
sample_size: 1
method: null
seeds: null
splits: null

# Other parameters
prompt_format: "superflue"