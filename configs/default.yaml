# Core settings
dataset: fomc
tasks:  # Multi-task list
  - fomc
  - numclaim
  - finer
mode: inference  # inference or evaluate
file_name: null  # Required for evaluate mode

# Model parameters
model: "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct"
max_tokens: 128
temperature: 0.0
top_p: 0.9
top_k: null
repetition_penalty: 1.0
batch_size: 1

# Dataset parameters
sample_size: 10
method: random
seeds: [42, 123, 456]
splits: [5768, 78516, 944601]

# Other parameters
prompt_format: "flame"