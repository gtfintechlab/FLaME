# Core settings
dataset: fomc
mode: inference  # inference or evaluate
file_name: null  # Required for evaluate mode

# Model parameters
model: "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
max_tokens: 128
temperature: 0.0
top_p: 0.9
top_k: null
repetition_penalty: 1.0
batch_size: 1

# Dataset parameters
sample_size: 10
method: random
seeds: [42, 123, 456]
splits: [5768, 78516, 944601]

# Other parameters
prompt_format: "flame"