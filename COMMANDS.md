`python3 src/together_code/inference.py --model "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo" --task "fpb" --max_tokens 100 --temperature 0.0 --top_p 0.9 --repetition_penalty 1.0 --prompt_format "superflue"`

 <!-- --api_key "{api_key}" --hf_token "{hf_token}"  -->