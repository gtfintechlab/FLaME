`python3 src/together_code/inference.py --model "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo" --task "fpb" --max_tokens 100 --temperature 0.0 --top_p 0.9 --repetition_penalty 1.0 --prompt_format "superflue"`


`python3 src/together_code/inference.py --model "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo" --task "fpb"`

`python main.py --config configs/default.yaml`